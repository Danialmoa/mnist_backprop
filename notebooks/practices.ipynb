{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from backPropMNIST import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Weights Initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = \"../datasets/mnist/mnist_train.csv\"\n",
    "data_test_path = \"../datasets/mnist/mnist_test.csv\"\n",
    "\n",
    "data = DataLoader(data_train_path).load_data()\n",
    "train_labels = data['5'].to_numpy()\n",
    "train_data = data.drop(columns=['5']).to_numpy()\n",
    "\n",
    "test_data = DataLoader(data_test_path).load_data()\n",
    "test_labels = test_data['7'].to_numpy()\n",
    "test_data = test_data.drop(columns=['7']).to_numpy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Name = Simple 2 Layer Network simTwoLayers\n",
    "input_size = train_data.shape[1]\n",
    "output_size = 10\n",
    "num_hidden_layers = 2\n",
    "hidden_size = [100, 100]\n",
    "activation_function = 'relu'\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "weights_methods = ['zero', 'random', 'he', 'xavier']\n",
    "experiments_number = 5\n",
    "model_name = 'simTwoLayers'\n",
    "accuracies = {'zero': [], 'random': [], 'he': [], 'xavier': []}\n",
    "\n",
    "for weights_method in weights_methods:\n",
    "    accuracies[weights_method] = []\n",
    "    for i in range(experiments_number):\n",
    "        print('-'*100)\n",
    "        print(f'Experiment {i+1} of {weights_method}')\n",
    "        network = NeuralNetwork(\n",
    "            input_size=input_size, \n",
    "            num_hidden_layers=num_hidden_layers, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=output_size, \n",
    "            activation_function=activation_function, \n",
    "            learning_rate=learning_rate, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            weights_method=weights_method\n",
    "        )\n",
    "        network.initialize_weights_biases()\n",
    "        network.train(train_data, train_labels)\n",
    "        os.makedirs(f'models/{model_name}/experiments/{weights_method}', exist_ok=True)\n",
    "        network.save_weights_biases(\n",
    "            f'models/{model_name}/experiments/{weights_method}/weights_{weights_method}_{i}.pkl', \n",
    "            f'models/{model_name}/experiments/{weights_method}/biases_{weights_method}_{i}.pkl'\n",
    "        )\n",
    "\n",
    "        predictions = network.test(test_data, test_labels)\n",
    "        accuracy = network.accuracy(test_labels, predictions)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        accuracies[weights_method].append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data.shape[1]\n",
    "output_size = 10\n",
    "num_hidden_layers = 2\n",
    "hidden_size = [100, 100]\n",
    "activation_function = 'relu'\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "weights_method = 'xavier'\n",
    "model_name = 'simTwoLayers_batchSize'\n",
    "\n",
    "accuracies = {'4': [], '8': [], '16': [], '32': [], '64': [], '128': []}\n",
    "batch_size_list = [4, 8, 16, 32, 64, 128]\n",
    "for batch_size in batch_size_list:\n",
    "    for i in range(experiments_number):\n",
    "        network = NeuralNetwork(\n",
    "            input_size=input_size, \n",
    "            num_hidden_layers=num_hidden_layers, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=output_size, \n",
    "            activation_function=activation_function, \n",
    "            learning_rate=learning_rate, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            weights_method=weights_method\n",
    "        )\n",
    "        network.initialize_weights_biases()\n",
    "        network.train(train_data, train_labels)\n",
    "        os.makedirs(f'models/{model_name}/experiments/{weights_method}', exist_ok=True)\n",
    "        network.save_weights_biases(\n",
    "        f'models/{model_name}/experiments/{weights_method}/weights_{batch_size}.pkl', \n",
    "            f'models/{model_name}/experiments/{weights_method}/biases_{batch_size}.pkl'\n",
    "        )\n",
    "\n",
    "        predictions = network.test(test_data, test_labels)\n",
    "        accuracy = network.accuracy(test_labels, predictions)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        accuracies[str(batch_size)].append(accuracy)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different architectures\n",
    "input_size = train_data.shape[1]\n",
    "batch_size = 64\n",
    "output_size = 10\n",
    "activation_function = 'relu'\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "weights_method = 'xavier'\n",
    "num_experiments = 5\n",
    "\n",
    "different_architectures = [\n",
    "    {'num_hidden_layers': 3, 'hidden_size': [400, 100, 50], 'name': 'md_400_100_50'},\n",
    "    {'num_hidden_layers': 3, 'hidden_size': [800, 200, 100], 'name': 'md_800_200_100'},\n",
    "    {'num_hidden_layers': 3, 'hidden_size': [1600, 400, 200], 'name': 'md_1600_400_200'},\n",
    "]\n",
    "\n",
    "\n",
    "model_name = 'simTwoLayers_architecture'\n",
    "accuracies = {\n",
    "    'md_400_100_50': [], \n",
    "    'md_800_200_100': [], \n",
    "    'md_1600_400_200': []\n",
    "}\n",
    "for architecture in different_architectures:\n",
    "    for i in range(num_experiments):\n",
    "        network = NeuralNetwork(\n",
    "            input_size=input_size,\n",
    "            num_hidden_layers=architecture['num_hidden_layers'],\n",
    "            hidden_size=architecture['hidden_size'],\n",
    "            output_size=output_size,\n",
    "            activation_function=activation_function,\n",
    "            learning_rate=learning_rate,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            weights_method=weights_method\n",
    "        )\n",
    "        network.initialize_weights_biases()\n",
    "        network.train(train_data, train_labels)\n",
    "        os.makedirs(f'models/{model_name}/experiments/{weights_method}', exist_ok=True)\n",
    "        network.save_weights_biases(\n",
    "            f'models/{model_name}/experiments/{weights_method}/weights_{architecture[\"name\"]}.pkl', \n",
    "            f'models/{model_name}/experiments/{weights_method}/biases_{architecture[\"name\"]}.pkl'\n",
    "        )\n",
    "\n",
    "        predictions = network.test(test_data, test_labels)\n",
    "        accuracy = network.accuracy(test_labels, predictions)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        accuracies[architecture['name']].append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in accuracies.items():\n",
    "    print(f\"{key}: {np.mean(value):.4f} Â± {np.std(value):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/two_layer_100_100_lr_0.001/run_1/'\n",
    "network = NeuralNetwork(\n",
    "        input_size=784,\n",
    "        num_hidden_layers=2,\n",
    "        hidden_size=[100, 100],\n",
    "        output_size=10,\n",
    "        activation_function='relu',\n",
    "        learning_rate=0.001,\n",
    "        epochs=1,  # Not used for inference\n",
    "        batch_size=1,  # Not used for inference\n",
    "        weights_method='xavier'\n",
    "    )\n",
    "network.initialize_weights_biases(\n",
    "    path_weights=f\"{model_path}/weights.npz\",\n",
    "    path_biases=f\"{model_path}/biases.npz\"\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.test(test_data[0].reshape(1, -1)/255, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "Image.fromarray(test_data[10].reshape(28, 28).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_shape = [weight.shape for weight in network.weights]\n",
    "weights_shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
